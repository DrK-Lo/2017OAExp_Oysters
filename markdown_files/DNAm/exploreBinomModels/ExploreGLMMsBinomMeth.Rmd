---
title: "Explore GLMM models for DNA methylation data"
author: "KE Lotterhos"
date: "9/26/2019"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Install packages

```{r cars}
packages_needed <- c("lme4", "multcomp", "devtools", "car", "MCMCglmm", "brms", "rstan")

for (i in 1:length(packages_needed)){
  if(!(packages_needed[i] %in% installed.packages())){install.packages(packages_needed[i])}
}

for (i in 1:length(packages_needed)){
  library( packages_needed[i], character.only = TRUE)
}
```

## Load data

Katie's working directory for this markdown:
setwd("~/Documents/GitHub/2017OAExp_Oysters/markdown_files/DNAm/exploreBinomModels")

You may have to set a different one.

```{r pressure, echo=FALSE}
mC <- readRDS("data/Final_mC_gene_5.RData")
uC <- readRDS("data/Final_umC_gene_5.RData")
meta_locus <- readRDS("data/Final_meta_gene_5.RData")
meta_samp <- readRDS("data/metadata_20190811.RData")

head(mC)
head(uC)
head(meta_locus)
head(meta_samp)

meta_samp$level <- paste(meta_samp$Treatment, meta_samp$Time, sep="_")

# remove excluded individual
meta_samp <- meta_samp[-which(meta_samp$ID==17099),]

# unit test - these should both be true
identical(names(mC), names(uC))
identical(names(uC), meta_samp$ID)
```

## Create some interesting cases
```{r}
# real data
a <- data.frame(mc=as.numeric(mC[1,]),
           uc=as.numeric(uC[1,]),
           level=meta_samp$level,
           Treatment = meta_samp$Treatment,
           Time = meta_samp$Time,
           tankID = meta_samp$tankID,
            Pop = meta_samp$Pop,
           size = as.numeric(mC[1,])+as.numeric(uC[1,]))

# real data with all 0 for unmeth in one treatment
b <- a
b$uc[b$level=='400_09'] <- 0
b$size <- b$mc+b$uc
b

# real data with all 0 for meth in one treatment
c <- a
c$mc[c$level=='400_09'] <- 0
c$size <- c$mc+c$uc
c

# real data with all one count for meth in one treatment
# compare to c for zero variance
d <- a
d$mc[d$level=='400_09'] <- 1
d$uc[d$level=='400_09'] <- 20
d$size <- d$mc+d$uc
d
```

## Test different models for real data

```{r}
boxplot(mc/(mc+uc) ~ Treatment*Time, data=a, las=2)
# No random effect of tank
m1 <- glm(cbind(mc,uc)~ Treatment*Time, data=a,family = "binomial")
summary(m1)
boxplot(m1$residuals~a$tankID)
boxplot(m1$residuals~a$Pop)
  # definitely some tank effects in the residuals
vif(m1) # variance inflation factor
AIC(m1)

m1.0 <- glm(cbind(mc,uc)~ Treatment*Time, data=a,family = "quasibinomial")
summary(m1.0)
boxplot(m1.0$residuals~a$tankID)
boxplot(m1.0$residuals~a$Pop)
  # definitely some tank effects in the residuals
vif(m1.0) # variance inflation factor

m1.1 <- glmer(cbind(mc,uc)~ Treatment*Time + (1|tankID), data=a,family = "binomial")
summary(m1.1)
boxplot(residuals(m1.1)~a$tankID)
boxplot(residuals(m1.1)~a$Pop)
  # this seems to be better, but still not perfectly accounting for residuals across tanks
vif(m1.1) # the inflation in size of the confidence ellipse or ellipsoid for the coefficients of the term in comparison with what would be obtained for orthogonal data.
AIC(m1.1)
  # improvement in model fit compared to m0
```

## Test different models for fake data "b"
One treatment has 100% methylation in all individuals

```{r}
boxplot(mc/(mc+uc) ~ Treatment*Time, data=b, las=2)

# No random effect of tank
m1 <- glm(cbind(mc,uc)~ Treatment*Time, data=b,family = "binomial")
summary(m1)
boxplot(m1$residuals~b$tankID)
boxplot(m1$residuals~b$Pop)
  # definitely some tank effects in the residuals
vif(m1) # variance inflation factor
  # hmmm

m1.1 <- glmer(cbind(mc,uc)~ Treatment*Time + (1|tankID), data=b,family = "binomial")
summary(m1.1)
boxplot(residuals(m1.1)~b$tankID)
boxplot(residuals(m1.1)~b$Pop)
  # this seems to be better, but we get that strange error message
vif(m1.1) # the inflation in size of the confidence ellipse or ellipsoid for the coefficients of the term in comparison with what would be obtained for orthogonal data.
```

## Test different models for fake data "c"
One treatment has 0% methylation in all individuals
```{r}
boxplot(mc/(mc+uc) ~ Treatment*Time, data=c, las=2)

# No random effect of tank
m1 <- glm(cbind(mc,uc)~ Treatment*Time, data=c,family = "binomial")
summary(m1)
boxplot(m1$residuals~c$tankID)
boxplot(m1$residuals~c$Pop)
  # definitely some tank effects in the residuals
vif(m1) # variance inflation factor
  # hmmm not good

m1.1 <- glmer(cbind(mc,uc)~ Treatment*Time + (1|tankID), data=c,family = "binomial")
summary(m1.1)
boxplot(residuals(m1.1)~c$tankID)
boxplot(residuals(m1.1)~c$Pop)
  # this seems to be better, but we get that strange error message
vif(m1.1) # the inflation in size of the confidence ellipse or ellipsoid for the coefficients of the term in comparison with what would be obtained for orthogonal data.

```


## Test different models for fake data "d"
One treatment has a count of 1 methylation in all individuals. This can be compared to dataset "c" to show the problem comes from fixation of counts of 0 and not from zero variance in a treatment.
```{r}
boxplot(mc/(mc+uc) ~ Treatment*Time, data=d, las=2)

# No random effect of tank
m1 <- glm(cbind(mc,uc)~ Treatment*Time, data=d,family = "binomial")
summary(m1)
boxplot(m1$residuals~d$tankID)
boxplot(m1$residuals~d$Pop)
  # definitely some tank effects in the residuals
vif(m1) # variance inflation factor
  # interesting, much better behaved

m1.1 <- glmer(cbind(mc,uc)~ Treatment*Time + (1|tankID), data=d,family = "binomial")
  # note no error message
summary(m1.1)
boxplot(residuals(m1.1)~d$tankID)
boxplot(residuals(m1.1)~d$Pop)
  # this seems to be better, but we get that strange error message
vif(m1.1) # the inflation in size of the confidence ellipse or ellipsoid for the coefficients of the term in comparison with what would be obtained for orthogonal data.
```


# Better understand what is causing error in datasets b and c


These show the error is caused by all individuals within a treatment having 0% or 100% methylation. Clearly, these are cases that are very interesting!

Googling "Warning message: In checkConv(attr(opt, "derivs"), opt$par, ctrl = control$checkConv, : Model failed to converge with max|grad| = 0.0129364 (tol = 0.001, component 1)"

This seems to be a very common error message, but I couldn't find a specific post that highlights the problem we discovered here.

## Let's try Bayesian MCMCglmm!

* Read Jared H's book in the Lotterhos Lab Reading / stats
* Good example [here](https://github.com/tmalsburg/MCMCglmm-intro)

```{r}

# These are default priors I found in some examples. I need to read up on these and

prior1=list(R=list(V=1, nu=0.002), G=list(G1=list(V=1, nu=0.002)))
prior2=list(R=list(V=1, nu=0.002), G=list(G1=list(V=1, nu=1,  
alpha.mu=0, alpha.V=100)))

# Real data
m2 <- MCMCglmm(cbind(mc,uc)~ Treatment*Time, random= ~tankID, 
               data=a,family = "multinomial2", prior=prior1)

plot(cbind(m2$VCV), pch=19, cex=0.2)
par(mfrow=c(4,2), mar=c(2,2,1,0))
plot(m2$Sol, auto.layout=F)
  # no autocorrelation in the traces, good!
summary(m2)
  # This result is interesting, more conservative P-values than
  # what we got with the glmer

# Fake data with 0's for methylation
m2 <- MCMCglmm(cbind(mc,uc)~ Treatment*Time, random= ~tankID, 
               data=c,family = "multinomial2", prior=prior1)

plot(cbind(m2$VCV), pch=19, cex=0.2)
par(mfrow=c(4,2), mar=c(2,2,1,0))
plot(m2$Sol, auto.layout=F)
  # some autocorrelation in the traces, not good!
summary(m2)

# Fake data with 0's for unmenthlated
b
m2 <- MCMCglmm(cbind(mc,uc)~ Treatment*Time, random= ~tankID, 
               data=c,family = "multinomial2", prior=prior1)

plot(cbind(m2$VCV), pch=19, cex=0.2)
par(mfrow=c(4,2), mar=c(2,2,1,0))
plot(m2$Sol, auto.layout=F)
  # lots of autocorrelation in the traces, not good! Will need to look into convergence issues
summary(m2)

# let's see if we can do better by changing the prior and increasing
# the number of iterations
m2 <- MCMCglmm(cbind(mc,uc)~ Treatment*Time, random= ~tankID, 
               data=c,family = "multinomial2", prior=prior2,
               thin   = 20,
               burnin = 3000,
               nitt   = 100000)
  # further increasing the thinning results in worse density plots;
  #
plot(cbind(m2$VCV), pch=19, cex=0.2)
par(mfrow=c(4,2), mar=c(2,2,1,0))
plot(m2$Sol, auto.layout=F)
summary(m2)
  # still some autocorrelation, but better than before
```

In this case we get an error message"In summary.glm(glm(cbind(MCMC_y, MCMC_y.additional) ~ 1, family = "quasibinomial",  :
  observations with zero weight not used for calculating dispersion"
  
There is one post on this:
https://stat.ethz.ch/pipermail/r-sig-mixed-models/2012q2/018129.html

Where the author of the package says this is not neccessarily anything to worry about.

## Let's try Bayesian brms!
[The github page has lots of great documentation](https://github.com/paul-buerkner/brms)

```{r}
vignette(package = "brms")
help("brm")

# No random effect of tank on real data
m3 <- brm(mc | trials(size)~ Treatment*Time, data=a,family = binomial())
  # takes a few seconds
summary(m3)
  # gives a similar result ot the GLM

# Add the random effect of tank
m3.1 <- brm(mc | trials(size)~ Treatment*Time + (1|tankID), data=a,family = binomial())
summary(m3.1)
plot(marginal_effects(m3.1), ask = FALSE)

# Try zero-inflated model
# https://paul-buerkner.github.io/brms/articles/brms_distreg.html
m3.2 <- brm(mc | trials(size)~ Treatment*Time + (1|tankID), data=a,family = zero_inflated_binomial())
summary(m3.2)
plot(marginal_effects(m3.2), ask = FALSE)
```

OK let's try the same thing, but with the data with 0's for unmethylated
```{r}
boxplot(mc/(mc+uc) ~ Treatment*Time, data=b, las=2)
# No random effect of tank on real data
m3 <- brm(mc | trials(size)~ Treatment*Time, data=b,family = binomial())
  # takes a few seconds
summary(m3)
  # gives a similar result ot the GLM
plot(marginal_effects(m3), ask = FALSE)

# Add the random effect of tank
m3.1 <- brm(mc | trials(size)~ Treatment*Time + (1|tankID), data=b,family = binomial(), iter=5000, control = list(max_treedepth = 15))
summary(m3.1)
plot(marginal_effects(m3.1), ask = FALSE)

quantile(posterior_samples(m3.1)$b_Treatment2800, c(0.0001, 0.9999))
quantile(posterior_samples(m3.1)$b_Time80, c(0.0001, 0.9999))
quantile(posterior_samples(m3.1)[,4], c(0.0001, 0.9999))
```

OK let's try the same thing, but with the data with 0's for methylated
Note this has some low count levels for the unmethylated section, need to fix that
```{r}
boxplot(mc/(mc+uc) ~ Treatment*Time, data=c, las=2)
# No random effect of tank on real data
m3 <- brm(mc | trials(size)~ Treatment*Time, data=c,family = binomial())
  # takes a few seconds
summary(m3)
pairs(m3)
  # gives a similar result ot the GLM
plot(marginal_effects(m3), ask = FALSE)
  # get warnings for this data

# Add the random effect of tank
m3.1 <- brm(mc | trials(size)~ Treatment*Time + (1|tankID), data=c,
            family = binomial(), iter=5000, control = list(max_treedepth = 15))
summary(m3.1)
plot(m3.1)

str(posterior_samples(m3.1))
quantile(posterior_samples(m3.1)$b_Treatment2800, c(0.0001, 0.9999))
quantile(posterior_samples(m3.1)$b_Time80, c(0.0001, 0.9999))
quantile(posterior_samples(m3.1)[,4], c(0.0001, 0.9999))

hypothesis(m3.1, "Time80 > 0", class="b", alpha=0.001)
  # Day 80 higher methylation than day 9
hypothesis(m3.1, "Time80 < 0", class="b", alpha=0.001)
  # Day 80 lower methylation than day 9
hypothesis(m3.1, "Treatment2800 > 0", class="b", alpha=0.001)
  # 2800 higher methylation than day 400
hypothesis(m3.1, "Treatment2800 < 0", class="b", alpha=0.001)
  # 2800 lower methylation than day 400
hypothesis(m3.1, "Treatment2800:Time80 > 0", class="b", alpha=0.001)
  # The change in 2800 from day 9 to 80 is greater than the change 
  # in the 400 treatment from day 9 to 80
hypothesis(m3.1, "Treatment2800:Time80 < 0", class="b", alpha=0.001)
  # The change in 2800 from day 9 to 80 is LESS than the change 
  # in the 400 treatment from day 9 to 80

plot(marginal_effects(m3.1), ask = FALSE)
  # get warnings for this data for iter = 2000 and default treedepth
  # get no warnings when increasing iter and treedepth
  # https://mc-stan.org/misc/warnings.html#maximum-treedepth-exceeded

pairs(m3.1)
  # in this plot want to look for iterations off the 1:1 line
  # colored in red or yellow 
  # https://mc-stan.org/misc/warnings.html

```


Let's try the model with recoding according to levels, so we can do specific hypothesis tests:

Results for fake data:

```{r}
levels(c$level)
# note that we need to re-code so that 400_09 is base
m4.1 <- brm(mc | trials(size)~ level + (1|tankID), data=c,
            family = binomial(), iter=5000, control = list(max_treedepth = 15, adapt_delta=0.99))
summary(m4.1)
plot(m4.1)
str(posterior_samples(m4.1))
plot(marginal_effects(m4.1), ask = FALSE)

alph = 0.0001

hypothesis(m4.1, "level2800_80=0", class="b", alpha=alph)
  # Is 2800_80 different from 2800_09

hypothesis(m4.1, "level2800_80=level400_09", class="b", alpha=alph)

hypothesis(m4.1, "level2800_80=level400_80", class="b", alpha=alph)

hypothesis(m4.1, "level400_09=level400_80", class="b", alpha=alph)

hypothesis(m4.1, "level400_09=0", class="b", alpha=alph)
  # Is day 9 at 400 the same as day 80 at 400

(h<-hypothesis(m4.1, "level400_09 + 2*Intercept= 2*Intercept + level2800_80 + level400_80", class="b", alpha=alph))
  # I think this is testing if Day 9 is different from Day 80
str(h)

(h<-hypothesis(m4.1, "level400_09 + level400_80 + 2*Intercept= 2*Intercept + level2800_80 ", class="b", alpha=alph))
  # I think this is testing if 400 is different from 2800

hypothesis(m4.1, "(Intercept+level400_09)-(Intercept)= (Intercept+level400_80)-(Intercept + level2800_80) ", class="b", alpha=alph)
  # I think this is testing if the difference between treatments at day 9 is different from the difference between treatments at day 80 (Interaction)
```



Results for real data:

Note that I had this error message:
`Warning messages:
1: There were 1 divergent transitions after warmup. Increasing adapt_delta above 0.8 may help.`

And as described in the paper I increased adapt_delta to 0.99


```{r}
levels(c$level)

get_prior(mc | trials(size)~ level + (1|tankID), data=a,
            family = binomial())
  # I think this means 3 df, 0 mean, and sd = 10 (large sd)  

# note that we need to re-code so that 400_09 is base
m4.1 <- brm(mc | trials(size)~ level + (1|tankID), data=a,
            family = binomial(), iter=5000, control = list(max_treedepth = 15, adapt_delta=0.99), sample_prior="yes")
# logit link is default

summary(m4.1)
plot(m4.1)
str(m4.1$data$level)
m4.1$data$level["contrasts"]
str(posterior_samples(m4.1))
str(marginal_effects(m4.1))
y <- plot(marginal_effects(m4.1), ask = FALSE, scale_y_continuous(name="percent methylation")) 
y + scale_y_continuous(name="percent methylation")

alph = 0.0001/2
(h_2800.80G2800.09_a0.0001 <- hypothesis(m4.1, "level2800_80>0", class="b", alpha=alph))
  # Is 2800_80 > 2800_09
  # This is an interesting case, becuase there is "strong evidence" of an effect, although not significant 

(h_2800.80L2800.09_a0.0001 <- hypothesis(m4.1, "level2800_80<0", class="b", alpha=alph))
  # Is 2800_80 > 2800_09

(h_400.09E2800.09_a0.0001 <-hypothesis(m4.1, "level400_09>0", class="b", alpha=alph))
  # Is day 9 at 400 the same as 2800_09

(h_400.80E2800.09_a0.0001 <-hypothesis(m4.1, "level400_80=0", class="b", alpha=alph))
  # Is day 80 at 400 the same as 2800_09

(h_2800.80E400.09_a0.0001 <- hypothesis(m4.1, "level2800_80=level400_09", class="b", alpha=alph))

(h_2800.80E400.80_a0.0001 <-hypothesis(m4.1, "level2800_80=level400_80", class="b", alpha=alph))

(h_400.09E400.80_a0.0001 <-hypothesis(m4.1, "level400_09=level400_80", class="b", alpha=alph))


(h_Time_a0.0001 <-hypothesis(m4.1, "level400_09 + 2*Intercept= 2*Intercept + level2800_80 + level400_80", class="b", alpha=alph))
  # I think this is testing if Day 9 is different from Day 80
str(h)

(h_Treatment_a0.0001 <-hypothesis(m4.1, "level400_09 + level400_80 + 2*Intercept= 2*Intercept + level2800_80 ", class="b", alpha=alph))
  # I think this is testing if 400 is different from 2800

(h_Interaction <-hypothesis(m4.1, "(Intercept+level400_09)-(Intercept)= (Intercept+level400_80)-(Intercept + level2800_80) ", class="b", alpha=alph))
  # I think this is testing if the difference between treatments at day 9 is different from the difference between treatments at day 80

str(h)
h$hypothesis$Star=="*"
```

Plan: Use last block of code as a baseline:

* Read up more on how to set priors and think about reasonalbe priors to set


* Order the levels so that 400_09 is the first level and recode the hypothesis tests accordingly. (Check that my coding of the hypothesis tests are correct first!). Then go over re-coding together to make sure it is correct.

* Read up more on the hypothesis tests and make sure we understand it. `?hypothesis` is a good place to start, and read Kass and Rafferty https://www.tandfonline.com/doi/abs/10.1080/01621459.1995.10476572
The function help says to avoid using default priors. Note that evidence ratio can be calculated for one-sided hypotheses but not two-sided hypotheses, and the evidence ratio can be interpreted as strength of evidence of an effect. I think we want to do one-sided hypotheses so we can store the Evidence Ratio, which according to Kass and Raftery log10(Evidence Ratio) > 1 is "strong evidence" and log10(Evidence Ratio) > 2 is "decisive evidence"

* Understand the contrasts to make sure hypothesis test is correct.

* Decide on alpha. This is Bayesian, so no way to correct for multiple tests. Here the help on `hypothesis` is also very good. There are 10,000 posterior samples, so `alpha=0.0001` means that only 1 of the posterior samples will lie outside the credible interval.

* Write up the methods for the paper.


* Test on top 10 loci and 10 random loci to make sure everything works

* Save the "Estimate" and the "Star" (h$hypothesis$Star=="*") from each hypothesis test, but be sure to note "alpha" in the results (e.g. `h_2800.80E2800.09_a0.0001`)

* Add logical to the function to output the plot if significant, but make sure to output a consistent plot for each locus: https://github.com/paul-buerkner/brms/issues/59 

* Pseudoparallize code to run (n loci)/(68 cores) on each core



Check some other types of data:
```{r}
boxplot(mc/size~level, data=a)
e <- a
e$uc[e$level=="400_09"] <- e$uc[e$level=="400_09"] + 5
e$size=e$mc + e$uc
boxplot(mc/size~level, data=e)


# note that we need to re-code so that 400_09 is base
m4.1 <- brm(mc | trials(size)~ level + (1|tankID), data=e,
            family = binomial(), iter=5000, control = list(max_treedepth = 15, adapt_delta=0.99))
summary(m4.1)
plot(m4.1)
str(posterior_samples(m4.1))
plot(marginal_effects(m4.1), ask = FALSE)

alph = 0.0001
(h_2800.80E2800.09_a0.0001 <- hypothesis(m4.1, "level2800_80=0", class="b", alpha=alph))
  # Is 2800_80 different from 2800_09

(h_400.09E2800.09_a0.0001 <-hypothesis(m4.1, "level400_09=0", class="b", alpha=alph))
  # Is day 9 at 400 the same as 2800_09

(h_400.80E2800.09_a0.0001 <-hypothesis(m4.1, "level400_80=0", class="b", alpha=alph))
  # Is day 80 at 400 the same as 2800_09

(h_2800.80E400.09_a0.0001 <- hypothesis(m4.1, "level2800_80=level400_09", class="b", alpha=alph))

(h_2800.80E400.80_a0.0001 <-hypothesis(m4.1, "level2800_80=level400_80", class="b", alpha=alph))

(h_400.09E400.80_a0.0001 <-hypothesis(m4.1, "level400_09=level400_80", class="b", alpha=alph))


(h_Time_a0.0001 <-hypothesis(m4.1, "level400_09 + 2*Intercept= 2*Intercept + level2800_80 + level400_80", class="b", alpha=alph))
  # I think this is testing if Day 9 is different from Day 80
str(h)

(h_Treatment_a0.0001 <-hypothesis(m4.1, "level400_09 + level400_80 + 2*Intercept= 2*Intercept + level2800_80 ", class="b", alpha=alph))
  # I think this is testing if 400 is different from 2800

(h_Interaction <-hypothesis(m4.1, "(Intercept+level400_09)-(Intercept)= (Intercept+level400_80)-(Intercept + level2800_80) ", class="b", alpha=0.001))
  # I think this is testing if the difference between treatments at day 9 is different from the difference between treatments at day 80

str(h)
```

# Other notes:

Note that I do not think we have a zero-inflated model. This model assumes that the sample is a “mixture” of two sorts of individuals: one group whose counts are generated by the standard binomial regression model, and another group (call them the absolute zero group) who have zero probability of a count greater than 0. 

In our case, we may have 0% or 100% methylation, but the counts are greater than 0 in at least one of the categories.

# Try Beta-binomial to account for overdispersion
(This gave all kinds of errors... will revisit later)

https://paul-buerkner.github.io/brms/articles/brms_customfamilies.html

beta_binomial2 <- custom_family(
  "beta_binomial2", dpars = c("mu", "phi"),
  links = c("logit", "log"), lb = c(NA, 0),
  type = "int", vars = "trials[n]"
)

stan_funs <- "
  real beta_binomial2_lpmf(int y, real mu, real phi, int T) {
    return beta_binomial_lpmf(y | T, mu * phi, (1 - mu) * phi);
  }
  int beta_binomial2_rng(real mu, real phi, int T) {
    return beta_binomial_rng(T, mu * phi, (1 - mu) * phi);
  }
"

stanvars <- stanvar(scode = stan_funs, block = "functions") +
  stanvar(as.integer(a$size), name = "trials")

m3.2 <- brm(mc | trials(size)~ Treatment*Time + (1|tankID), data=a,family = beta_binomial2, stanvars = stanvars)

summary(m3.2)
