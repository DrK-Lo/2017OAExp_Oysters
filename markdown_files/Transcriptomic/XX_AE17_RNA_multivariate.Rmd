---
title: "02 Salmon Pipeline"
author: "adowneywall"
date: "6/11/2019"
output: 
  html_document:
    keep_md: true
editor_options: 
  chunk_output_type: console
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(DESeq2)
library(edgeR)
library(ashr)
library(vegan)
library(sf)
library(adegenet)
library(ggplot2)
library(ape)
library(factoextra) # for the fviz_eig function
```

## **Script Description**  

**Brief Overview** : This script performs a series of basic multivariate approaches to explore the whole genome expression profiles of the 24 oyster RNAseq samples. In partiular this includes:
* A permanova (implemented in the package vegan, called adonis)  
* An RDA (implemented in vegan)
* A DAPC with a focus on treatment(implemented in adegenet)

## **Data**  

Data Description:
* Using count matrices post filtration. Genes that were express in at least 5 individuals within a single treatment were retained. I explored using several variations of count matriced that have been normalized or transformed to better account for either (a) differences among library sizes among samples, (b) large variation in expression within a sample between genes. Specifically, I look at:
    * non-normalized count matrix with log2 transformation
    * normalized (implemented using `TMM` procedure in `EdgeR`) count matrix with log2 transformation
    * normalized (same prodecure as above) with individual weight approach from limma (using `voomWithQualityWeights()`)

Steps:  
* Read in dataframes
    * Metadata data.frame including, treatment, time, population, lane of sequencing, and variable that contains each unique combination level between treatment and time.  
    * Count matrices : gene (or transcript) abundance matrix  
* Perform PERMANOVA using `adonis` from `vegan` package.
* Perform PCA 
* Perform DAPC



### Current files
```{r fileREADIN}
## Meta Data for the Model
model<-readRDS("/home/downeyam/Github/2017OAExp_Oysters/input_files/meta/metadata_20190811.RData")

### Transcript Matrix ###
#tran <- readRDS("/home/downeyam/Github/2017OAExp_Oysters/input_files/RNA/references/STAR_gnomon_tximportGeneFile.RData")

### Gene Matrix ###
# Version 1 - Count matrix w/o edgeR normalization and standard voom (log2-cpm) transformation
gc <-  readRDS("/home/downeyam/Github/2017OAExp_Oysters/results/Transcriptomic/DGEListObj_filterApproach2.RData")
manual_transformation <- log2(cpm(gc$counts+0.5))
gc_voom <- voom(gc)

manual_transformation[1:5,1:5]
gc_voom$E[1:5,1:5]
# Interesting using voom (which is suppose to transform data to log2-counts per million (logCPM), is very similar but not identical to manual performing this transformation on the raw counts.

gc_qualityweights <-  readRDS("/home/downeyam/Github/2017OAExp_Oysters/results/Transcriptomic/DGEListObj_withIndWeights_filterApproach2_plannedContrastMatrix.RData")

# Examining the impact of transformation among approaches
# Expression for the first 5 genes and samples
manual_transformation[1:5,1:5] # manual tranforming data into counts per million (CPM) and then taking the log2
gc_voom$E[1:5,1:5] # Peforming the same operation but in the function voom
gc_qualityweights$E[1:5,1:5] # Look at the transformation after the edgeR normalization step. This object represents the version of the

# Checking out the library size variation between methods
# Should be similar since they are all transformed into cpm and log transformed
colSums(manual_transformation)
colSums(gc_voom$E) # Transformed by no normalization factors
plot(colSums(gc_voom$E)~gc_voom$targets$lib.size)
#Interesting the differences in lib. size among samples after transformation is not driven, 
#by variation in lib. size from the sequencer.
colSums(gc_qualityweights$E) # Transformed with voom + normalization (TMM from edgeR)

# Manual transformation vs. voom no normalization
plot(colSums(manual_transformation)~colSums(gc_voom$E)) # Very well correlated
#Voom vs. voom with normalization
plot(colSums(gc_voom$E)~colSums(gc_qualityweights$E),
     xlim=c(72000,75000),ylim=c(72000,75000))
abline(b=1,a=0)
# Voom with normalization manually included vs voom with normalization
plot(gc_qualityweights$targets$norm.factors*colSums(gc_voom$E)~colSums(gc_qualityweights$E),
     xlim=c(65000,85000),ylim=c(65000,85000))
abline(b=1,a=0)
#Looking at the lib. sizes for each sample after transformation from different methods shows pretty poor correlation when compared to post normalized counts.

```

# Based on Gene (and isoform) level data

### PERMANOVA (implements using adonis from vegan package)

* Testing for statistic differential between treatment, time, and treatment:time  

```{r}
# Standard voom 
(out_gc <- adonis(t(gc_voom$E)~Treatment*Time+Pop+Lane,data=model,permutations = 5000))

(out_gc <- adonis(t(gc_voom$E*gc_voom$weights)~Treatment*Time+Pop+Lane,data=model,permutations = 5000))

# Counts from quality weights EList object
(out_gc <- adonis(t(gc_qualityweights$E)~Treatment*Time+Pop+Lane,data=model,permutations = 5000))
# Multiple counts by individual weights
(out_gc <- adonis(t(gc_qualityweights$E*gc_qualityweights$weights)~Treatment*Time+Pop+Lane,data=model,permutations = 5000))
#(out_tc <- adonis(t(tc_reduce)~Treatment*Time+Pop+Lane,data=model,permutations = 5000))
```

### Plotting data with RDA  

### Plot in multivariate space with RDA (treatment and time)
```{r}
### Just using the count matrix generated after filtering and standard normalization pipeline ###
ge_pca <- prcomp(t(gc_qualityweights$E))
fviz_eig(ge_pca)
# Quick pca plot
fviz_pca_ind(ge_pca, 
             #label = "none", # hide individual labels
             habillage = model$SFV, # color by groups
             palette = c("#00AFBB", "#E7B800", "#FC4E07","green"),
             addEllipses = TRUE, axes = c(1,2),ellipse.level=0.90 # Concentration ellipses  
)

### Removing individual 17005 which seems like an outlier ###
ge_pca_outlierRM <- prcomp(t(gc_qualityweights$E[,-1]))
fviz_eig(ge_pca_outlierRM)
# Quick pca plot
fviz_pca_ind(ge_pca_outlierRM, 
             #label = "none", # hide individual labels
             habillage = model$SFV[-1], # color by groups
             palette = c("#00AFBB", "#E7B800", "#FC4E07","green"),
             addEllipses = TRUE, axes = c(1,2),ellipse.level=0.90 # Concentration ellipses   
            
)

### Use individual weights ###
ge_pca <- prcomp(t(gc_qualityweights$E*gc_qualityweights$weights))
fviz_eig(ge_pca)
# Quick pca plot
fviz_pca_ind(ge_pca, 
             #label = "none", # hide individual labels
             habillage = model$SFV, # color by groups
             palette = c("#00AFBB", "#E7B800", "#FC4E07","green"),
             addEllipses = TRUE, axes = c(1,2),ellipse.level=0.90 # Concentration ellipses 
)

fviz_pca_ind(ge_pca, 
             #label = "none", # hide individual labels
             habillage = model$SFV, # color by groups
             palette = c("#00AFBB", "#E7B800", "#FC4E07","green"),
             addEllipses = TRUE, axes = c(2,3),ellipse.level=0.90 # Concentration ellipses 
)
# Interesting based on the PCA we see the most separation by time x treatment in the second and third
# PCs compared to other count matrix variations, but we didn;t see anything significant in the PERMANOVA. 
# One reason for this is looking at the first PC we see most of the variation is due to individual variation.
```

```{r}
#### Custom PCA ####
pca <- prcomp(t(gc_qualityweights$E))
eigs <- pca$sdev^2

color_comb <- c("lightblue4","royalblue3","tomato","darkred") # colors for population 
model$colors <- "" 
model$colors[model$SFV == unique(model$SFV)[1]] <-  color_comb[2]
model$colors[model$SFV == unique(model$SFV)[2]] <-  color_comb[1]
model$colors[model$SFV == unique(model$SFV)[3]] <-  color_comb[4]
model$colors[model$SFV == unique(model$SFV)[4]] <-  color_comb[3]
model$pch <- 16
model$pch[model$colors == color_comb[2] | model$colors == "darkred"] <- 10

ordiplot(pca,type="n",
         xlab=paste0("PC1  (",round(eigs[1] / sum(eigs)*100,1),"% Variance Explained)"),
         ylab=paste0("PC2  (",round(eigs[2] / sum(eigs)*100,1),"% Variance Explained)"))

orditorp(pca,display="sites",labels = FALSE,col=model$colors,cex = 2,pch = model$pch)
ordispider(pca,model$SFV,col = color_comb,lwd=2.5)
legend(x=c(4,14),y=c(12,17),
       legend = c("Day 09 : Ambient",
                  "Day 80 : Ambient",
                  "Day 09 : 2800",
                  "Day 80 : 2800"),
       pch = c(16,10,16,10),col=color_comb,xpd = .25)
text(x = 6 ,y = -5, 
     paste0("P_Treatment = ",round(out_gc$aov.tab$`Pr(>F)`[1],3),"*"),pos = 4)
text(x = 6 ,y = -6, 
     paste0("P_Time = ",round(out_gc$aov.tab$`Pr(>F)`[2],5),"*"),pos=4)
text(x = 6 ,y = -7, 
     paste0("P_Interaction = ",round(out_gc$aov.tab$`Pr(>F)`[5],3)),pos=4)

### Plot colored by population ###
ordiplot(prin_comp,type="n",
         xlab=paste0("PC1 ",round(eigs[1] / sum(eigs)*100,1),"% Variance Explained)"),
         ylab=paste0("PC2 ",round(eigs[2] / sum(eigs)*100,1),"% Variance Explained)"))
orditorp(prin_comp,display="sites",labels = FALSE,col=model$Pop,cex = 2,pch = 16)
legend(x=100,y=100,legend = c("Ipswich","Rowley 1","Rowley 2"),pch = 16,col=unique(model$Pop),xpd = .25)
```

### TWO STEP DAPC: first create discriminant function from TP 9 samples and predict coordinates on df for day 80 samples.  
  
**Creating DF by treatment with first timepoint**  
```{r}
gc_comb <- gc_qualityweights$E*gc_qualityweights$weights
early_time_counts_V1 <- gc_comb[,model$Day == 9]
early_time_counts_V2 <- gc_qualityweights$E[,model$Day == 9]
early_time_meta <- model[model$Day == 9,]

dapc_treatment_V1_2 <- dapc(t(early_time_counts_V1),early_time_meta$treatment,n.pca=2,n.da=1)
dapc_treatment_V2_8<-dapc(t(early_time_counts),early_time_meta$treatment,n.pca=8,n.da=1)
# PCs = 8
# clusters = 1

early_time_meta$V1_2 <- unlist(dapc_treatment_V1_2$ind.coord[,1])
early_time_meta$V2_8 <- unlist(dapc_treatment_V2_8$ind.coord[,1])

ggplot(early_time_meta,aes(V2_8,fill=as.factor(treatment),colour=as.factor(treatment))) + 
  geom_density(alpha=0.1) + xlim(-15,15) + 
  labs(title="Discriminant Function for Treatment on Day 9 (based on 8 PCs)",
       x="Discriminant function 1",
       colour="Treatment",
       fill="Treatment") +
  theme_bw() +
  scale_color_manual(values=c("deepskyblue2","firebrick1")) +
  scale_fill_manual(values=c("deepskyblue2","firebrick1"))
```

Looking at which genes are driving the patterns between the two treatments
```{r}
contrib_treatment <- loadingplot(dapc_treatment_V2_8$var.contr, axis=1,thres=.05, lab.jitter=1)
```

Looking at the most important locus based on loading
```{r}
# head(gc)
# gc_majorLoading <- gc[row.names(gc) == "LOC111102518",]
# majorLoading_counts <- as.data.frame(cbind(Trt=model$Treatment,Time=model$Time,SFV=model$SFV,Pop=model$Pop,(LOC111104151=gc_majorLoading)))
# 
# ggplot(majorLoading_counts,aes(x=as.factor(SFV),y=log10(LOC111104151))) + geom_boxplot() + 
#   labs(x= c("SFV"))
```

**Mapping 
Day 80 samples**  
```{r}
late_time_counts_V1 <- gc_comb[,model$Day == 80]
late_time_counts_V2 <- gc_qualityweights$E[,model$Day == 80]
late_time_meta <- model[model$Day == 80,]

predict_values_V1_2 <- predict.dapc(dapc_treatment_V1_2,t(late_time_counts_V1))
predict_values_V2_8 <- predict.dapc(dapc_treatment_V2_8,t(late_time_counts_V2))

late_time_meta$V1_2 <-unlist(predict_values_V1_2$ind.scores[,1])
late_time_meta$V2_8 <-unlist(predict_values_V2_8$ind.scores[,1])

whole_meta<- rbind(early_time_meta,late_time_meta)

ggplot(whole_meta,aes(V1_2,fill=as.factor(interaction(Day,treatment)),colour=as.factor(interaction(Day,treatment)))) + 
  geom_density(alpha=0.1) + xlim(-12,12) + 
  labs(x="Discriminant function 1",
       colour="Day.Treatment",
       fill="Day.Treatment") +
  theme_bw() +
  scale_color_manual(values=c("lightblue4","blue4","tomato","darkred")) +
  scale_fill_manual(values=c("lightblue4","blue4","tomato1","darkred"))

D9_400 <- whole_meta[whole_meta$SFV == "09.400",]
D9_400_Density <- density(D9_400$dt)
D9_2800 <- whole_meta[whole_meta$SFV == "09.2800",]
D9_2800_Density <- density(D9_2800$dt)
D80_400 <- whole_meta[whole_meta$SFV == "80.400",]
D80_400_Density <- density(D80_400$dt)
D80_2800 <- whole_meta[whole_meta$SFV == "80.2800",]
D80_2800_Density <- density(D80_2800$dt)

plot(D9_400_Density, main="",xlim=c(-10,7),ylim=c(0,0.9),
     xlab="Discriminant Function 1")
polygon(D9_400_Density, col=alpha("lightblue",0.8), border="lightblue")
polygon(D9_2800_Density, col=alpha("tomato",0.8), border="red3")
polygon(D80_400_Density, col=alpha("blue",0.9), 
        border="blue",density = 20,cex=100)
polygon(D80_2800_Density, col=alpha("red3",0.9),
        border="red3",density = 20,angle=0,cex=5)
legend(x=c(-10,-4.3),y=c(0.9,0.73),legend=c("Day 09 : Ambient","Day 09 : 2800 ","Day 80 : Ambient","Day 80 : 2800"),
       fill = c(alpha("lightblue",0.8),alpha("tomato",0.8),alpha("blue",0.7),alpha("red3",0.7)),
       density = c(1000,1000,50,50),angle = c(0,0,45,0))
```

### DAPC based on combined time*treatment factor  
  
**Creating DF by treatment with first timepoint**  
```{r}
dapc_SFV_10<-dapc(t(gc),model$SFV,n.pca=8,n.da=3)
# PCs = 10
# clusters = 3
output <- data.frame(Trt=model$Treatment,Time=model$Time,dapc_SFV_10$ind.coord)

ggplot(output,aes(x=LD1,y=LD2,fill=as.factor(interaction(Trt,Time)),colour=as.factor(interaction(Trt,Time)))) + 
  geom_point(aes(size=5)) + #geom_density(alpha=0.1) + #xlim(-28,28) + 
  labs(title="DAPC for Treatment*Time Combination",
       x="Discriminant function 1",
       y="Discriminant function 2",
       colour="Treatment",
       fill="Treatment") +
    theme_bw() +
  scale_color_manual(values=c("deepskyblue2","firebrick1","blue4","darkred")) +
  scale_fill_manual(values=c("deepskyblue2","firebrick1","blue4","darkred"))
```

Looking at contribution of individual genes
```{r}
contrib_SFV <- loadingplot(dapc_SFV_10$var.contr, axis=2,thres=.07, lab.jitter=1)
```

## Final figure
```{r}
par(mfrow=c(2,1))
dim(gc_reduce)
prin_comp<-rda(t(gc_reduce),scale = TRUE)

color_comb <- c("lightblue4","royalblue3","tomato","darkred") # colors for population 
model$colors <- "" 
model$colors[model$SFV == unique(model$SFV)[1]] <-  color_comb[2]
model$colors[model$SFV == unique(model$SFV)[2]] <-  color_comb[1]
model$colors[model$SFV == unique(model$SFV)[3]] <-  color_comb[4]
model$colors[model$SFV == unique(model$SFV)[4]] <-  color_comb[3]
model$pch[model$colors == color_comb[1]] <- 16
model$pch[model$colors == color_comb[3]] <- 17
model$pch[model$colors == color_comb[2]] <- 1
model$pch[model$colors == color_comb[4]] <- 2

ordiplot(prin_comp,type="n",
         xlab=paste0("PC1  (",round(eigs[1] / sum(eigs)*100,1),"% Variance Explained)"),
         ylab=paste0("PC2  (",round(eigs[2] / sum(eigs)*100,1),"% Variance Explained)"))
orditorp(prin_comp,display="sites",labels = FALSE,col=model$colors,cex = 2,pch = model$pch)
#ordiellipse(prin_comp,model$SFV,conf=0.90,col = color_comb,lwd = 3)
ordispider(prin_comp,
           model$SFV,
           col = color_comb,
           lwd=2.5)

legend(x=c(4,16),y=c(10.2,17),
       legend = c("Day 09 : Ambient",
                  "Day 80 : Ambient",
                  "Day 09 : 2800",
                  "Day 80 : 2800"),
       pch = c(16,1,17,2),
       col=color_comb,
       xpd = .25,bty="n",
       cex=1.2)
text(x = 6 ,y = -4.6, 
     paste0("P_Treatment = ",round(out_gc$aov.tab$`Pr(>F)`[1],3),"*"),pos = 4)
text(x = 6 ,y = -6.2, 
     paste0("P_Time = ",round(out_gc$aov.tab$`Pr(>F)`[2],5),"*"),pos=4)
text(x = 6 ,y = -7.8, 
     paste0("P_Interaction = ",round(out_gc$aov.tab$`Pr(>F)`[5],3)),pos=4)

text(x = -25 ,y = 20, 
     "A",cex = 2.2,xpd=NA)
late_time_counts <- gc_reduce[,model$Day == 80]
late_time_meta <- model[model$Day == 80,]

predict_values <- predict.dapc(dapc_treatment_10,t(late_time_counts))
late_time_meta$dt <-unlist(predict_values$ind.scores[,1])

whole_meta<- rbind(early_time_meta,late_time_meta)

D9_400 <- whole_meta[whole_meta$SFV == "09.400",]
D9_400_Density <- density(D9_400$dt)
D9_2800 <- whole_meta[whole_meta$SFV == "09.2800",]
D9_2800_Density <- density(D9_2800$dt)
D80_400 <- whole_meta[whole_meta$SFV == "80.400",]
D80_400_Density <- density(D80_400$dt)
D80_2800 <- whole_meta[whole_meta$SFV == "80.2800",]
D80_2800_Density <- density(D80_2800$dt)

plot(D9_400_Density, main="",xlim=c(-10,7),ylim=c(0,0.9),
     xlab="Discriminant Function 1",cex=1.2)
polygon(D9_400_Density, col=alpha("lightblue",0.8), border="lightblue")
polygon(D9_2800_Density, col=alpha("tomato",0.8), border="red3")
polygon(D80_400_Density, col=alpha("royalblue3",0.9), 
        border="royalblue3",density = 20,cex=100)
polygon(D80_2800_Density, col=alpha("red3",0.9),
        border="red3",density = 20,angle=0,cex=5)
legend(x=c(-10,-4.9),y=c(0.9,0.65),bty="n",cex=1.2,
       legend=c("Day 09 : Ambient",
                "Day 80 : Ambient",
                "Day 09 : 2800 ",
                "Day 80 : 2800"),
       fill = c(alpha("lightblue",0.8),
                alpha("royalblue3",0.7),
                alpha("tomato",0.8),
                alpha("red3",0.7)),
       density = c(1000,
                   50,
                   1000,
                   50),
       angle = c(0,
                 45,
                 0,
                 0))
text(x = -11.88 ,y = 1.03, 
     "B",cex = 2.2,xpd=NA)
```

# Based on Transcript level data

### PERMANOVA (implements using adonis from vegan package)

* Testing for statistic differential between treatment, time, and treatment:time  

```{r}
(out <- adonis(t(tc_reduce)~Treatment*Time+Pop+Lane,data=model,permutations = 5000))
```

### Plotting data with RDA with isoform data

### Plot in multivariate space with RDA (treatment and time)
```{r}
prin_comp<-rda(t(tc_reduce), scale=FALSE)
sum_pri <- summary(prin_comp)
pca_scores<-scores(prin_comp)

pca <- prcomp(t(tc_reduce))
eigs <- pca$sdev^2

head(sum_pri$species)
color_comb <- c("deepskyblue2","blue4","firebrick1","darkred") # colors for population 
model$colors <- "" 
model$colors[model$SFV == unique(model$SFV)[1]] <-  color_comb[2]
model$colors[model$SFV == unique(model$SFV)[2]] <-  color_comb[1]
model$colors[model$SFV == unique(model$SFV)[3]] <-  color_comb[4]
model$colors[model$SFV == unique(model$SFV)[4]] <-  color_comb[3]

ordiplot(prin_comp,type="n",
         xlab=paste0("PC1 ",round(eigs[1] / sum(eigs)*100,1),"% Variance Explained)"),
         ylab=paste0("PC2 ",round(eigs[2] / sum(eigs)*100,1),"% Variance Explained)"))
orditorp(prin_comp,display="sites",labels = FALSE,col=model$colors,cex = 2,pch = 16,)
#ordiellipse(prin_comp,model$SFV,conf=0.90,col = color_comb,lwd = 3)
ordispider(prin_comp,model$SFV,col = color_comb,lwd=2.5)
legend(x=100,y=150,legend = c("Day09_Control","Day80_Control","Day09_OA","Day80_OA"),pch = 16,col=color_comb,xpd = .25)
text(x = -538 ,y = -300, paste0("Adonis P_Treatment = ",out$aov.tab$`Pr(>F)`[1],"*"))
text(x = -550 ,y = -360, paste0("Adonis P_Duration = ",out$aov.tab$`Pr(>F)`[2],"*"))
text(x = -540 ,y = -420, paste0("Adonis P_Interaction = ",out$aov.tab$`Pr(>F)`[5]))
```


